# üß™ TP1 : Cycle de Vie et D√©ploiement d'un Mod√®le de Deep Learning (MNIST)

Ce d√©p√¥t contient le premier Travail Pratique de la s√©rie "Deep Learning Engineering Labs" ax√©e sur la mise en ≈ìuvre des principes du MLOps. Il couvre l'int√©gralit√© du cycle de vie d'un mod√®le, de l'entra√Ænement √† la conteneurisation en vue du d√©ploiement.

---

## üöÄ Objectifs et Comp√©tences Acquises

L'objectif principal est de transformer un script d'entra√Ænement acad√©mique en un service professionnel pr√™t pour la production.

1.  **Mod√©lisation DL :** Construction et entra√Ænement d'un r√©seau de neurones dense (MLP) pour la classification des chiffres manuscrits MNIST avec Keras/TensorFlow.
2.  **MLOps & Tra√ßabilit√© :** Int√©gration de **MLflow** pour le suivi des hyperparam√®tres, des m√©triques et l'archivage du mod√®le.
3.  **Conteneurisation :** Cr√©ation d'une API d'inf√©rence avec **Flask/Gunicorn** et empaquetage dans une image **Docker** optimis√©e.
4.  **Ing√©nierie Logicielle :** Structuration du projet, gestion des d√©pendances (`requirements.txt`) et versionnement (`.gitignore`).

---

## üõ†Ô∏è Stack Technique

| Cat√©gorie | Outil | Version | Description |
| :--- | :--- | :--- | :--- |
| **Framework DL** | TensorFlow / Keras | 2.x | Construction, entra√Ænement et s√©rialisation du mod√®le. |
| **MLOps** | MLflow | R√©cent | Tra√ßage des exp√©rimentations pour la reproductibilit√©. |
| **API Web** | Flask / Gunicorn | R√©cent | Serveur WSGI pour exposer le mod√®le via une API REST. |
| **Conteneurisation** | Docker | R√©cent | Environnement isol√© pour le d√©ploiement. |
| **Langage** | Python | 3.9+ | Langage de d√©veloppement principal. |

---

## ‚öôÔ∏è Structure du Projet

Le projet est structur√© selon les bonnes pratiques MLOps pour s√©parer le code source, les mod√®les et la documentation.

```text
tp1-mnist-lifecycle/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ train.py      # Script d'entra√Ænement, incluant le logging MLflow.
‚îÇ   ‚îî‚îÄ‚îÄ app.py        # API Flask pour le service d'inf√©rence.
‚îú‚îÄ‚îÄ models/           # R√©pertoire de sortie pour le mod√®le sauvegard√© (mnist_model.h5).
‚îú‚îÄ‚îÄ report/           # Rapport du TP au format LaTeX (main.tex).
‚îú‚îÄ‚îÄ Dockerfile        # Fichier d'instructions pour construire le conteneur.
‚îî‚îÄ‚îÄ requirements.txt  # D√©pendances Python n√©cessaires au projet.
````

-----

## üöÄ Instructions d'Ex√©cution

### Pr√©requis

  * [Git](https://git-scm.com/)
  * [Python 3.9+](https://www.python.org/downloads/)
  * [Docker](https://www.docker.com/get-started) (Doit √™tre en cours d'ex√©cution)

### 1\. Configuration et Entra√Ænement

**NOTE :** Assurez-vous que l'environnement virtuel est activ√© et que les d√©pendances sont install√©es (voir le `requirements.txt` √† la racine du monorepo).

```bash
# Se placer dans le r√©pertoire du TP
cd deep-learning-engineering-labs/tp1-mnist-lifecycle

# Entra√Æner le mod√®le et logguer l'exp√©rimentation
python src/train.py
```

### 2\. Suivi des Exp√©rimentations (MLflow)

Apr√®s l'ex√©cution, les r√©sultats sont stock√©s dans le dossier `mlruns/`. Lancez l'interface utilisateur pour visualiser l'exp√©rience :

```bash
# Remonter √† la racine du monorepo (o√π se trouve le dossier mlruns/)
cd .. 

# Lancer le serveur MLflow
mlflow ui

# Acc√©dez √† l'interface via votre navigateur √† [http://127.0.0.1:5000](http://127.0.0.1:5000)
```

### 3\. Conteneurisation (Docker)

La construction de l'image utilise une approche multi-stage pour minimiser la taille finale du conteneur.

```bash
# S'assurer d'√™tre dans le dossier tp1-mnist-lifecycle/
docker build -t mnist-api:latest .
```

### 4\. D√©marrage et Test de l'API

D√©marrez le conteneur en mappant le port 5000 du conteneur sur le port 5000 de la machine h√¥te.

```bash
# Lancement du conteneur en arri√®re-plan (-d)
docker run -d -p 5000:5000 --name mnist-service mnist-api:latest

# --- Test de l'√©tat de sant√© (Health Check) ---
# V√©rifie que l'API est en ligne et que le mod√®le est charg√©
curl http://localhost:5000/health
# R√©sultat attendu : {"model_loaded": true, "status": "ok"}
```

#### Test d'Inf√©rence (Exemple)

Pour tester la pr√©diction, vous devez envoyer un array de 784 valeurs (pixels normalis√©s, 0-1) d'une image MNIST.

```bash
# Exemple de corps de requ√™te JSON (Image d'un "0" ou d'un "1" tr√®s simplifi√©)
# Vous devrez utiliser un exemple r√©el pour un test valide.
REQUEST_BODY='{"image": [0.0, 0.0, ..., 1.0, 1.0, 0.0, ...]}' 

curl -X POST \
  -H "Content-Type: application/json" \
  -d "$REQUEST_BODY" \
  http://localhost:5000/predict

# R√©sultat attendu : {"prediction": 7, "confidence": "99.98%", "probabilities": [...]}
```
