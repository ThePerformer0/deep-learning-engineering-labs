üß™ TP3 : CNN & Vision (CIFAR-10)
================================

## 1. Contexte et continuit√© (TP1 ‚Üí TP2 ‚Üí TP3)
- **TP1 (MNIST, MLP + Dropout)** : bases du DL, logging MLflow, conteneurisation.
- **TP2 (MNIST am√©lior√©)** : r√©gularisation L2, BatchNorm, EarlyStopping, suivi avanc√©.
- **TP3 (CIFAR-10, CNN)** : on passe aux images couleur 32√ó32√ó3. Les convolutions exploitent la structure spatiale et les blocs r√©siduels facilitent l‚Äôentra√Ænement de r√©seaux plus profonds. On r√©utilise les r√©flexes d‚Äôindustrialisation vus en TP1/TP2 (structure projet, Docker, m√©triques).

## 2. Notions cl√©s et utilit√©
- **Convolution + stride/padding** : extraire des motifs locaux (bords, textures) avec partage de poids ‚Üí bien plus efficace que du Dense sur des images.
- **Pooling (Max/Avg)** : r√©duire la dimension et gagner en robustesse aux translations.
- **Flatten / GlobalAveragePooling** : passer des cartes de features aux couches denses pour la d√©cision finale.
- **Blocs r√©siduels (ResNet)** : skip connection pour limiter le vanishing gradient et permettre des r√©seaux plus profonds/stables.
- **CIFAR-10** : plus complexe que MNIST (couleur, fonds vari√©s) ‚Üí montre l‚Äôint√©r√™t des convolutions.
- **Parall√®le TP2** : on peut ajouter L2/Dropout/BatchNorm sur conv et denses comme dans le TP2 si besoin de r√©gularisation.

## 3. Structure du projet
```text
tp3-cnn-vision/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ cnn_classification.py   # Pr√©traitement CIFAR-10, CNN basique, mini-ResNet
‚îú‚îÄ‚îÄ report/
‚îÇ   ‚îî‚îÄ‚îÄ main.tex                # Rapport TP3 (questions th√©oriques + r√©sultats)
‚îú‚îÄ‚îÄ requirements.txt            # D√©pendances locales (TF, numpy, matplotlib, pillow)
‚îú‚îÄ‚îÄ Dockerfile                  # Image pour entra√Æner le CNN
‚îî‚îÄ‚îÄ models/                     # (optionnel) sauvegardes de mod√®les
```

## 4. Installation rapide
```bash
cd tp3-cnn-vision
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

## 5. Ex√©cution (CPU par d√©faut)
```bash
cd tp3-cnn-vision
python src/cnn_classification.py          # CNN basique (2 conv + 2 pool + denses)
```
- Pour tester le mini-ResNet illustratif : ouvrir `cnn_classification.py` et passer `use_resnet=True` dans `main()`.
- Entra√Ænement par d√©faut : 10 √©poques, batch_size=64, validation_split=0.1.
- T√©l√©chargement CIFAR-10 : ~170 Mo au premier lancement.

## 6. Ce que fait le script
1) **Chargement/Pr√©traitement** : normalisation [0,1], one-hot des labels, affichage des shapes.  
2) **Mod√®le basique** : Conv(32, 3√ó3, same) ‚Üí MaxPool(2√ó2) ‚Üí Conv(64, 3√ó3, same) ‚Üí MaxPool ‚Üí Flatten ‚Üí Dense(512) ‚Üí Dense(10, softmax).  
3) **Mini-ResNet (option)** : 3 blocs r√©siduels (32) ; (64, stride 2) ; (64) + GlobalAveragePooling + Dense.  
4) **Entra√Ænement** : Adam + categorical_crossentropy, suivi accuracy/val_accuracy.  
5) **√âvaluation** : affiche test accuracy / test loss.

## 7. Parall√®le avec TP1/TP2 (r√©utiliser les bonnes pratiques)
- **R√©gularisation** : ajouter L2/Dropout/BatchNorm si surapprentissage (cf. TP2).
- **EarlyStopping + logging** : reprendre le callback d‚Äôearly stopping et le tracking MLflow du TP2 si besoin de suivi d‚Äôexp√©riences.
- **Conteneurisation** : m√™me logique que TP1/TP2 pour reproductibilit√©.

## 8. Docker
```bash
cd tp3-cnn-vision
docker build -t tp3-cnn:latest .
docker run --rm tp3-cnn:latest
```
- Monter un volume pour conserver mod√®les/logs : `-v $(pwd)/models:/app/models`.

## 9. R√©sultats indicatifs (CPU)
- CNN basique 10 √©poques : pr√©cision test typique ~70 % (peut varier selon mat√©riel/seed).
- Le mini-ResNet peut apporter une stabilit√© suppl√©mentaire si vous ajoutez BatchNorm/L2.

## 10. Rapport LaTeX
- `report/main.tex` : r√©ponses th√©oriques (convolution/pooling, skip connections, segmentation U-Net, d√©tection bbox, style transfer avec VGG16).
- Compilation : `cd report && pdflatex main.tex`.

## 11. Pistes d‚Äôapprofondissement
- Ajouter **BatchNorm** apr√®s les conv, **Dropout** apr√®s denses, **L2** sur kernels.
- Brancher **EarlyStopping** et un logger (MLflow / TensorBoard).
- Tester un **scheduler de learning rate** ou un optimiseur diff√©rent (SGD momentum).
- Sauvegarder le mod√®le dans `models/` (`model.save(...)`).

## 12. Rappels pratiques
- GPU (CUDA) recommand√© pour acc√©l√©rer l‚Äôentra√Ænement CIFAR-10.
- V√©rifier l‚Äôespace disque (download ~170 Mo).
- Sur CPU, r√©duire `epochs` si besoin pour des tests rapides.

