ü©∫ TP4 : Segmentation avanc√©e (U-Net) et donn√©es 3D
==================================================

## 1. Contexte (continuation TP1‚ÜíTP2‚ÜíTP3‚ÜíTP4)
- **TP1** : MLP sur MNIST, logging MLflow, conteneurisation.
- **TP2** : R√©gularisation (L2, Dropout, BatchNorm), EarlyStopping, tracking avanc√©.
- **TP3** : CNN sur CIFAR-10, blocs r√©siduels, vision 2D.
- **TP4** : Segmentation s√©mantique avec U-Net (m√©dical) + introduction Conv3D (volumique). On r√©utilise les bonnes pratiques MLOps : structuration, Docker, tracking MLflow, m√©triques custom.

## 2. Objectifs p√©dagogiques
- Comprendre la sortie d‚Äôun mod√®le de segmentation (carte H√óW√óclasses).
- Impl√©menter U-Net (encoder/decoder + skip concatenation).
- Utiliser des pertes et m√©triques adapt√©es : Dice, IoU, BCE+Dice.
- Tracer les exp√©riences (MLflow) avec noms explicites d‚Äôarchitecture/optimiseur/perte.
- Introduire Conv3D pour donn√©es volum√©triques et ses contraintes m√©moire.

## 3. Structure du projet
```text
tp4-advanced-vision/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ unet_segmentation.py   # U-Net 2D, m√©triques Dice/IoU, MLflow, d√©mo Conv3D
‚îú‚îÄ‚îÄ report/
‚îÇ   ‚îî‚îÄ‚îÄ main.tex               # Rapport th√©orique + lien repo
‚îú‚îÄ‚îÄ requirements.txt           # D√©pendances (TF, numpy, mlflow‚Ä¶)
‚îú‚îÄ‚îÄ Dockerfile                 # Entra√Ænement/exp√©rimentation en conteneur
‚îî‚îÄ‚îÄ models/                    # (optionnel) sauvegardes de mod√®les
```

## 4. Installation
```bash
cd tp4-advanced-vision
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

## 5. Script U-Net (src/unet_segmentation.py)
- **Pr√©traitement** : charge des donn√©es simul√©es si aucun dataset fourni (`--use-dummy-data` par d√©faut).
- **Mod√®le** : U-Net 2D avec conv_block (Conv-BN-ReLU), encoder (MaxPool), decoder (Conv2DTranspose), skip concatenation.
- **Pertes/M√©triques** : Dice, IoU, BCE, BCE+Dice (passez `--loss bce_dice` pour les cas d√©s√©quilibr√©s).
- **MLflow** : `TP4_Segmentation_Unet` avec nom de run explicite (`unet_<loss>_<opt>_img<input>`), log des hyperparams, m√©triques finales, et sauvegarde du mod√®le.
- **Conv3D d√©mo** : bloc simple avec logging MLflow (`--do-conv3d-demo`) pour illustrer la volum√©trie.

### Ex√©cution rapide (donn√©es simul√©es)
```bash
python src/unet_segmentation.py --epochs 3 --batch-size 8
```
Options utiles :
- `--loss {bce,dice,bce_dice}` (par d√©faut bce_dice)
- `--no-mlflow` pour d√©sactiver le logging
- `--do-conv3d-demo` pour lancer l‚Äôexemple Conv3D + MLflow

### Brancher vos donn√©es
- Remplacez la fonction `load_data()` pour retourner `(x_train, y_train), (x_val, y_val), input_shape`.
- Les masques doivent √™tre binaires (0/1) et align√©s avec les images.

## 6. Docker
```bash
cd tp4-advanced-vision
docker build -t tp4-unet:latest .
docker run --rm tp4-unet:latest python src/unet_segmentation.py --epochs 3
```
- Montez un volume pour conserver mod√®les/logs : `-v $(pwd)/models:/app/models -v $(pwd)/mlruns:/app/mlruns`.

## 7. R√©sultats attendus (donn√©es simul√©es)
- Les m√©triques (Dice/IoU) sont surtout l√† pour v√©rifier le pipeline ; avec des donn√©es r√©elles, comparez les runs via MLflow et surveillez le d√©s√©quilibre foreground/background.

### Exemple de run (donn√©es simul√©es, CPU)
```
python src/unet_segmentation.py --epochs 3 --batch-size 8
```
R√©sultats observ√©s (dummy data) :
- Train (fin epoch 3) : accuracy ‚âà 0.91, Dice ‚âà 0.78, IoU ‚âà 0.64, loss ‚âà 0.51
- Val (fin epoch 3) : accuracy ‚âà 0.67, Dice ‚âà 0.52, IoU ‚âà 0.35, loss ‚âà 1.15
- MLflow run : `unet_bce_dice_adam_img128` (exp√©rience `TP4_Segmentation_Unet`)
‚ö†Ô∏è Warnings MLflow : `artifact_path` d√©pr√©ci√©, absence de signature/input_example (peut √™tre ajout√© si vous fournissez un exemple d‚Äôentr√©e).

### Exemple de d√©mo Conv3D
```
python src/unet_segmentation.py --do-conv3d-demo
```
Cr√©e une exp√©rience `TP4_Conv3D_Volumetric` avec un run `conv3d_baseline` (logging de la config mod√®le et m√©triques simul√©es).

## 8. Liens et rapport
- Rapport : `report/main.tex` (questions : sortie segmentation, r√¥le du decoder U-Net, diff√©rence des skips vs ResNet, pertes adapt√©es, m√©triques Dice/IoU, Conv3D et compromis m√©moire).
- Repo : https://github.com/ThePerformer0/deep-learning-engineering-labs/tree/main/tp4-advanced-vision

## 9. Parall√®le avec les TPs pr√©c√©dents
- R√©utilisez L2/Dropout/BatchNorm (TP2) si surapprentissage.
- R√©utilisez EarlyStopping/ReduceLROnPlateau pour stabiliser la convergence.
- Conservez la discipline MLflow (noms de runs explicites, log m√©triques custom).

## 10. Explications p√©dagogiques cl√©s
- **Sortie segmentation** : carte H√óW√óC (ou H√óW√ó1 en binaire), donc on optimise pixel par pixel, pas un seul label global.
- **U-Net vs ResNet** : U-Net concat√®ne (skip) pour restaurer les d√©tails perdus au pooling ; ResNet additionne pour faciliter le gradient dans un r√©seau tr√®s profond.
- **Pertes adapt√©es** : BCE seule p√©nalise peu les faux n√©gatifs quand le foreground est minuscule ; BCE+Dice ou Dice am√©liorent le recouvrement sur les petites r√©gions.
- **M√©triques** : Dice (F1 segmentation) est plus indulgent que IoU ; IoU p√©nalise davantage les faux positifs et reste plus strict.
- **Conv3D** : noyaux 3D (kD√ókH√ókW) explorent aussi la profondeur (empilement de slices). Co√ªt m√©moire √©lev√© ‚Üí limiter filtres, taille de noyau, profondeur d‚Äôentr√©e, ou travailler par patchs/ROIs.
- **MLOps** : noms de runs explicites (`unet_<loss>_<opt>_img<input>`), log des hyperparams et m√©triques custom, sauvegarde du mod√®le. Montez un volume `mlruns/` dans Docker pour conserver l‚Äôhistorique.

