# üöÄ TP2 : Am√©lioration des Mod√®les de Deep Learning

Ce d√©p√¥t contient le deuxi√®me Travail Pratique de la s√©rie "Deep Learning Engineering Labs" ax√©e sur l'am√©lioration des performances des mod√®les de deep learning. Ce TP s'appuie sur le TP1 et introduit des techniques avanc√©es de r√©gularisation et d'optimisation pour am√©liorer les performances du mod√®le baseline.

---

## üéØ Objectifs et Comp√©tences Acquises

L'objectif principal est d'am√©liorer les performances du mod√®le baseline du TP1 en appliquant des techniques avanc√©es de r√©gularisation et d'optimisation.

1. **R√©gularisation L2** : Impl√©mentation de la r√©gularisation des poids pour r√©duire le surapprentissage
2. **Batch Normalization** : Stabilisation de l'entra√Ænement et acc√©l√©ration de la convergence
3. **Early Stopping** : Arr√™t automatique de l'entra√Ænement pour √©viter le surapprentissage
4. **Tracking avanc√© MLflow** : Suivi d√©taill√© des m√©triques de validation et comparaison des mod√®les

---

## üîß Techniques d'Am√©lioration Impl√©ment√©es

### 1. R√©gularisation L2 (L2 Regularization)

La r√©gularisation L2 ajoute une p√©nalit√© sur les poids √©lev√©s du mod√®le, ce qui aide √† r√©duire le surapprentissage.

**Impl√©mentation :**
- Utilisation de `kernel_regularizer=regularizers.l2(lambda)` sur les couches Dense
- Coefficient de r√©gularisation : `l2_lambda = 0.001` (hyperparam√®tre ajustable)

**Avantages :**
- R√©duit la complexit√© du mod√®le en p√©nalisant les poids √©lev√©s
- Am√©liore la g√©n√©ralisation sur les donn√©es de test
- Formule : `loss = original_loss + lambda * sum(weights¬≤)`

### 2. Batch Normalization

La normalisation par lots normalise les activations de chaque couche, stabilisant l'entra√Ænement.

**Impl√©mentation :**
- Ajout de `BatchNormalization()` apr√®s la premi√®re couche Dense
- Activ√©e par d√©faut (`use_batch_norm = True`)

**Avantages :**
- Stabilise l'entra√Ænement en normalisant les distributions d'activation
- Permet d'utiliser des taux d'apprentissage plus √©lev√©s
- R√©duit la sensibilit√© √† l'initialisation des poids
- Acc√©l√®re la convergence

### 3. Early Stopping

Arr√™t automatique de l'entra√Ænement lorsque la performance sur le jeu de validation cesse de s'am√©liorer.

**Impl√©mentation :**
- Callback `EarlyStopping` avec patience de 5 epochs
- Surveille `val_loss` et restaure automatiquement les meilleurs poids
- √âvite le surapprentissage et √©conomise le temps de calcul

**Configuration :**
- `patience = 5` : Nombre d'epochs sans am√©lioration avant arr√™t
- `monitor = "val_loss"` : M√©trique surveill√©e
- `restore_best_weights = True` : Restaure les poids du meilleur epoch

### 4. Am√©liorations du Tracking MLflow

**Nouvelles m√©triques track√©es :**
- `final_val_accuracy` : Pr√©cision finale sur le jeu de validation
- `best_val_accuracy` : Meilleure pr√©cision de validation atteinte
- `final_val_loss` : Perte finale sur le jeu de validation
- `best_val_loss` : Meilleure perte de validation atteinte
- `actual_epochs` : Nombre r√©el d'epochs utilis√©s (si early stopping)

**Nouveaux hyperparam√®tres track√©s :**
- `l2_lambda` : Coefficient de r√©gularisation L2
- `use_batch_norm` : Flag indiquant l'utilisation de Batch Normalization
- `early_stopping_patience` : Patience pour l'early stopping
- `regularization_applied` : Flag indiquant l'application de r√©gularisation

---

## üìä Comparaison TP1 vs TP2

### Architecture du Mod√®le

| Caract√©ristique | TP1 (Baseline) | TP2 (Am√©lior√©) |
|----------------|----------------|----------------|
| **Couches Dense** | 2 (512, 10) | 2 (512, 10) |
| **Dropout** | ‚úÖ (0.2) | ‚úÖ (0.3) |
| **R√©gularisation L2** | ‚ùå | ‚úÖ (Œª=0.001) |
| **Batch Normalization** | ‚ùå | ‚úÖ |
| **Early Stopping** | ‚ùå | ‚úÖ (patience=5) |
| **Epochs** | 5 | 20 (avec early stopping) |

### Hyperparam√®tres

| Param√®tre | TP1 | TP2 |
|-----------|-----|-----|
| `epochs` | 5 | 20 |
| `batch_size` | 128 | 128 |
| `optimizer` | adam | adam |
| `dropout_rate` | 0.2 | 0.3 |
| `l2_lambda` | - | 0.001 |
| `use_batch_norm` | - | True |
| `early_stopping_patience` | - | 5 |

### R√©sultats Obtenus

#### TP2 - Mod√®le Am√©lior√© (R√©sultats de l'ex√©cution)

| M√©trique | Valeur |
|----------|--------|
| **Test Accuracy** | **97.62%** (0.9762) |
| **Test Loss** | **0.1673** |
| **Best Val Accuracy** | **97.82%** (0.9782) |
| **Best Val Loss** | **0.1675** |
| **Final Val Accuracy** | **97.80%** (0.9780) |
| **Final Val Loss** | **0.1675** |
| **Epochs utilis√©s** | 20 (early stopping non d√©clench√©) |

#### Comparaison des Performances

**Am√©liorations observ√©es :**
- ‚úÖ **Stabilit√©** : Le mod√®le montre une convergence plus stable gr√¢ce √† Batch Normalization
- ‚úÖ **G√©n√©ralisation** : La r√©gularisation L2 et le dropout augment√© (0.3) am√©liorent la g√©n√©ralisation
- ‚úÖ **Optimisation** : Early Stopping permet d'√©viter le surapprentissage tout en permettant plus d'epochs si n√©cessaire
- ‚úÖ **Tracking** : M√©triques de validation d√©taill√©es pour un meilleur suivi

**Note :** Pour une comparaison pr√©cise avec le TP1, il est recommand√© d'ex√©cuter le mod√®le baseline du TP1 dans les m√™mes conditions et de comparer les m√©triques via MLflow.

---

## üõ†Ô∏è Stack Technique

| Cat√©gorie | Outil | Description |
| :--- | :--- | :--- |
| **Framework DL** | TensorFlow / Keras | 2.x - Construction et entra√Ænement du mod√®le am√©lior√© |
| **MLOps** | MLflow | Tracking avanc√© des exp√©rimentations avec m√©triques de validation |
| **Langage** | Python | 3.9+ - Langage de d√©veloppement principal |

---

## ‚öôÔ∏è Structure du Projet

```text
tp2-improving-deep-models/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ train.py      # Script d'entra√Ænement avec am√©liorations (L2, BN, Early Stopping)
‚îú‚îÄ‚îÄ models/           # R√©pertoire de sortie pour le mod√®le sauvegard√©
‚îú‚îÄ‚îÄ report/           # Rapport du TP au format LaTeX (main.tex)
‚îú‚îÄ‚îÄ Dockerfile        # Fichier d'instructions pour construire le conteneur
‚îú‚îÄ‚îÄ requirements.txt  # D√©pendances Python n√©cessaires au projet
‚îî‚îÄ‚îÄ README.md         # Ce fichier
```

---

## üöÄ Instructions d'Ex√©cution

### Pr√©requis

* [Git](https://git-scm.com/)
* [Python 3.9+](https://www.python.org/downloads/)
* Environnement virtuel activ√© avec les d√©pendances install√©es

### 1. Configuration et Entra√Ænement

**NOTE :** Assurez-vous que l'environnement virtuel est activ√© et que les d√©pendances sont install√©es (voir le `requirements.txt` √† la racine du monorepo).

```bash
# Se placer dans le r√©pertoire du TP
cd deep-learning-engineering-labs/tp2-improving-deep-models

# Entra√Æner le mod√®le am√©lior√© et logguer l'exp√©rimentation
python src/train.py
```

### 2. Suivi des Exp√©rimentations (MLflow)

Apr√®s l'ex√©cution, les r√©sultats sont stock√©s dans le dossier `mlruns/`. Lancez l'interface utilisateur pour visualiser l'exp√©rience :

```bash
# Remonter √† la racine du monorepo (o√π se trouve le dossier mlruns/)
cd .. 

# Lancer le serveur MLflow
mlflow ui

# Acc√©dez √† l'interface via votre navigateur √† http://127.0.0.1:5000
```

Dans l'interface MLflow, vous pouvez :
- Comparer les runs du TP1 et TP2
- Visualiser l'√©volution des m√©triques de validation
- Analyser l'impact des diff√©rents hyperparam√®tres

### 3. Conteneurisation avec Docker

Le projet inclut un Dockerfile pour permettre l'ex√©cution dans un environnement conteneuris√©.

**Construction de l'image :**
```bash
# Se placer dans le r√©pertoire du TP
cd deep-learning-engineering-labs/tp2-improving-deep-models

# Construire l'image Docker
docker build -t tp2-mnist-training:latest .
```

**Ex√©cution du conteneur :**
```bash
# Ex√©cuter le script d'entra√Ænement dans le conteneur
docker run --rm tp2-mnist-training:latest

# Ex√©cuter avec un volume pour persister les r√©sultats MLflow
docker run --rm -v $(pwd)/mlruns:/app/mlruns tp2-mnist-training:latest

# Ex√©cuter avec un volume pour sauvegarder les mod√®les
docker run --rm \
  -v $(pwd)/mlruns:/app/mlruns \
  -v $(pwd)/models:/app/models \
  tp2-mnist-training:latest
```

**Avantages de la conteneurisation :**
- Reproductibilit√© : Environnement identique sur toutes les machines
- Isolation : D√©pendances isol√©es du syst√®me h√¥te
- Portabilit√© : Ex√©cutable sur n'importe quelle machine avec Docker
- CI/CD : Facilite l'int√©gration dans des pipelines d'automatisation

### 4. Comparaison avec le Mod√®le Baseline (TP1)

Pour comparer les performances :

1. **Via MLflow UI :**
   - Ouvrir l'interface MLflow
   - S√©lectionner les exp√©riences "TP1_MNIST_Deep_Learning_LifeCycle" et "TP2_Improving_Deep_Models"
   - Comparer les m√©triques `test_accuracy` et `test_loss`

2. **Via le code :**
   ```python
   import mlflow
   
   # Charger les runs
   client = mlflow.tracking.MlflowClient()
   tp1_runs = client.search_runs(experiment_ids=["TP1_experiment_id"])
   tp2_runs = client.search_runs(experiment_ids=["TP2_experiment_id"])
   
   # Comparer les m√©triques
   ```

---

## üìà Analyse des R√©sultats

### Interpr√©tation des M√©triques

1. **Test Accuracy (97.62%)** : Pr√©cision finale sur le jeu de test, indicateur principal de performance
2. **Best Val Accuracy (97.82%)** : Meilleure pr√©cision atteinte sur le jeu de validation
3. **Gap Train-Val** : Diff√©rence entre train et validation (indicateur de surapprentissage)
   - Dans notre cas, le gap est faible, indiquant une bonne g√©n√©ralisation

### Impact des Techniques

1. **R√©gularisation L2** : 
   - R√©duit le surapprentissage en p√©nalisant les poids √©lev√©s
   - Am√©liore la g√©n√©ralisation

2. **Batch Normalization** :
   - Stabilise l'entra√Ænement
   - Permet une convergence plus rapide et stable

3. **Early Stopping** :
   - √âvite le surapprentissage en arr√™tant l'entra√Ænement au bon moment
   - √âconomise le temps de calcul

4. **Dropout augment√© (0.2 ‚Üí 0.3)** :
   - R√©duit davantage le risque de surapprentissage
   - Force le mod√®le √† √™tre plus robuste

---

## üî¨ Exp√©rimentations Futures

Pour aller plus loin, vous pouvez exp√©rimenter avec :

1. **Hyperparam√®tres √† ajuster :**
   - `l2_lambda` : Tester diff√©rentes valeurs (0.0001, 0.001, 0.01)
   - `dropout_rate` : Tester diff√©rentes valeurs (0.2, 0.3, 0.4, 0.5)
   - `early_stopping_patience` : Ajuster selon les besoins

2. **Architecture :**
   - Ajouter des couches suppl√©mentaires
   - Tester diff√©rentes tailles de couches cach√©es
   - Exp√©rimenter avec diff√©rentes fonctions d'activation

3. **Optimisation :**
   - Tester diff√©rents optimiseurs (RMSprop, SGD avec momentum)
   - Ajuster le learning rate
   - Impl√©menter un learning rate scheduler

---

## üìù Notes Techniques

### Ordre des Couches

L'ordre recommand√© pour les couches est :
1. **Dense** (avec r√©gularisation L2)
2. **Batch Normalization** (si activ√©)
3. **Activation** (ReLU)
4. **Dropout**

Dans notre impl√©mentation, Batch Normalization est plac√© apr√®s Dense et avant Dropout, ce qui est une pratique courante.

### Early Stopping

L'early stopping surveille `val_loss` et s'arr√™te si aucune am√©lioration n'est observ√©e pendant `patience` epochs. Les meilleurs poids sont automatiquement restaur√©s gr√¢ce √† `restore_best_weights=True`.

---

## üéì Conclusion

Le TP2 d√©montre l'importance des techniques de r√©gularisation et d'optimisation pour am√©liorer les performances des mod√®les de deep learning. Les techniques impl√©ment√©es (L2, Batch Normalization, Early Stopping) permettent d'obtenir un mod√®le plus robuste et g√©n√©ralisable.

**Points cl√©s √† retenir :**
- La r√©gularisation est essentielle pour √©viter le surapprentissage
- Batch Normalization stabilise et acc√©l√®re l'entra√Ænement
- Early Stopping optimise le temps d'entra√Ænement tout en pr√©servant les performances
- Le tracking MLflow permet de comparer et analyser les diff√©rentes exp√©rimentations

---

## üìö R√©f√©rences

- [TensorFlow Keras Documentation](https://www.tensorflow.org/api_docs/python/tf/keras)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [Deep Learning Book - Regularization](https://www.deeplearningbook.org/contents/regularization.html)

